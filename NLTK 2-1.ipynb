{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Memo28/nltk/blob/master/NLTK%202-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLOMPMRVID78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "417b3b9e-17dc-48a9-f3e7-081968da44ca"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.util import ngrams\n",
        "from operator import itemgetter \n",
        "\n",
        "#Pasamos a minusculas\n",
        "s = \"Le temps est un grand maître, dit-on, le malheur est qu'il tue ses élèves.\"\n",
        "s = s.lower()\n",
        "\n",
        "#Con una expresion regular encontramos tokenizamos (pasmos a palabras)\n",
        "#el string\n",
        "tokenizer = RegexpTokenizer(\"[a-zA-Z'éèî]+\")\n",
        "s_tokenized  = tokenizer.tokenize(s)\n",
        "s_tokenized\n",
        "\n",
        "#Generamos 4Grams de cada palabra poniendo como pad un _ a la derecha e izquierda\n",
        "generate_4grams = []\n",
        "for word in s_tokenized:\n",
        "  generate_4grams.append(list(ngrams(word,4, pad_left=True, pad_right=True, left_pad_symbol='_', right_pad_symbol='_')))\n",
        "\n",
        "generate_4grams = [word for sublist in generate_4grams for word in sublist]\n",
        "\n",
        "generate_4grams[:2]\n",
        "\n",
        "\n",
        "\n",
        "ng_list_4grams = generate_4grams\n",
        "#enumerate le agrega un index numero al arreglo ex (['0','_'],['1','_'])\n",
        "#Concatenamos los n grams de \n",
        "#('_', '_', '_', 'l') == ['___l',\n",
        "\n",
        "for idx, val in enumerate(generate_4grams):\n",
        "  ng_list_4grams[idx] = ''.join(val)\n",
        "\n",
        "ng_list_4grams\n",
        "\n",
        "\n",
        "#Ordenamos los 4grams por frecuencia\n",
        "\n",
        "freq_4grams = {}\n",
        "\n",
        "for ngram in ng_list_4grams:\n",
        "  #Sino esta en el arreglo lo agregamos con el valor de 1\n",
        "  if(ngram) not in freq_4grams:\n",
        "    freq_4grams.update({ngram : 1})\n",
        "  else:\n",
        "    #Si ya se encuentra en el arreglo lo encontramos y le agregamos una ocurrenca\n",
        "    ngram_ocurrences = freq_4grams[ngram]\n",
        "    freq_4grams.update({ngram : ngram_ocurrences + 1})\n",
        "\n",
        "#Ordenamos el arreglo de menor a mayor y nos quedamos con solo los 300 con mayor repeticion    \n",
        "freq_4grams_sorted = sorted(freq_4grams.items(), key=itemgetter(1), reverse=True)[0:300]    \n",
        "freq_4grams_sorted"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('e___', 4),\n",
              " ('s___', 3),\n",
              " ('t___', 3),\n",
              " ('___l', 2),\n",
              " ('__le', 2),\n",
              " ('_le_', 2),\n",
              " ('le__', 2),\n",
              " ('___t', 2),\n",
              " ('___e', 2),\n",
              " ('__es', 2),\n",
              " ('_est', 2),\n",
              " ('est_', 2),\n",
              " ('st__', 2),\n",
              " ('n___', 2),\n",
              " ('___m', 2),\n",
              " ('__ma', 2),\n",
              " ('es__', 2),\n",
              " ('__te', 1),\n",
              " ('_tem', 1),\n",
              " ('temp', 1),\n",
              " ('emps', 1),\n",
              " ('mps_', 1),\n",
              " ('ps__', 1),\n",
              " ('___u', 1),\n",
              " ('__un', 1),\n",
              " ('_un_', 1),\n",
              " ('un__', 1),\n",
              " ('___g', 1),\n",
              " ('__gr', 1),\n",
              " ('_gra', 1),\n",
              " ('gran', 1),\n",
              " ('rand', 1),\n",
              " ('and_', 1),\n",
              " ('nd__', 1),\n",
              " ('d___', 1),\n",
              " ('_maî', 1),\n",
              " ('maît', 1),\n",
              " ('aîtr', 1),\n",
              " ('ître', 1),\n",
              " ('tre_', 1),\n",
              " ('re__', 1),\n",
              " ('___d', 1),\n",
              " ('__di', 1),\n",
              " ('_dit', 1),\n",
              " ('dit_', 1),\n",
              " ('it__', 1),\n",
              " ('___o', 1),\n",
              " ('__on', 1),\n",
              " ('_on_', 1),\n",
              " ('on__', 1),\n",
              " ('_mal', 1),\n",
              " ('malh', 1),\n",
              " ('alhe', 1),\n",
              " ('lheu', 1),\n",
              " ('heur', 1),\n",
              " ('eur_', 1),\n",
              " ('ur__', 1),\n",
              " ('r___', 1),\n",
              " ('___q', 1),\n",
              " ('__qu', 1),\n",
              " (\"_qu'\", 1),\n",
              " (\"qu'i\", 1),\n",
              " (\"u'il\", 1),\n",
              " (\"'il_\", 1),\n",
              " ('il__', 1),\n",
              " ('l___', 1),\n",
              " ('__tu', 1),\n",
              " ('_tue', 1),\n",
              " ('tue_', 1),\n",
              " ('ue__', 1),\n",
              " ('___s', 1),\n",
              " ('__se', 1),\n",
              " ('_ses', 1),\n",
              " ('ses_', 1),\n",
              " ('___é', 1),\n",
              " ('__él', 1),\n",
              " ('_élè', 1),\n",
              " ('élèv', 1),\n",
              " ('lève', 1),\n",
              " ('èves', 1),\n",
              " ('ves_', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6jmgQJ2PN9W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2884cf1-09c0-4d3b-e099-05a0d36de367"
      },
      "source": [
        "#Obteniendo N-Gramas de 1,2,3 y 4 de extension\n",
        "from nltk import everygrams\n",
        "\n",
        "s_clean = ' '.join(s_tokenized)\n",
        "s_clean\n",
        "\n",
        "def ngram_extractor(sent):\n",
        "    return [''.join(ng) for ng in everygrams(sent.replace(' ', '_ _'), 1, 4) \n",
        "            if ' ' not in ng and '\\n' not in ng and ng != ('_',)]\n",
        "\n",
        "ngram_extractor(s_clean)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['l',\n",
              " 'e',\n",
              " 't',\n",
              " 'e',\n",
              " 'm',\n",
              " 'p',\n",
              " 's',\n",
              " 'e',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'n',\n",
              " 'g',\n",
              " 'r',\n",
              " 'a',\n",
              " 'n',\n",
              " 'd',\n",
              " 'm',\n",
              " 'a',\n",
              " 'î',\n",
              " 't',\n",
              " 'r',\n",
              " 'e',\n",
              " 'd',\n",
              " 'i',\n",
              " 't',\n",
              " 'o',\n",
              " 'n',\n",
              " 'l',\n",
              " 'e',\n",
              " 'm',\n",
              " 'a',\n",
              " 'l',\n",
              " 'h',\n",
              " 'e',\n",
              " 'u',\n",
              " 'r',\n",
              " 'e',\n",
              " 's',\n",
              " 't',\n",
              " 'q',\n",
              " 'u',\n",
              " \"'\",\n",
              " 'i',\n",
              " 'l',\n",
              " 't',\n",
              " 'u',\n",
              " 'e',\n",
              " 's',\n",
              " 'e',\n",
              " 's',\n",
              " 'é',\n",
              " 'l',\n",
              " 'è',\n",
              " 'v',\n",
              " 'e',\n",
              " 's',\n",
              " 'le',\n",
              " 'e_',\n",
              " '_t',\n",
              " 'te',\n",
              " 'em',\n",
              " 'mp',\n",
              " 'ps',\n",
              " 's_',\n",
              " '_e',\n",
              " 'es',\n",
              " 'st',\n",
              " 't_',\n",
              " '_u',\n",
              " 'un',\n",
              " 'n_',\n",
              " '_g',\n",
              " 'gr',\n",
              " 'ra',\n",
              " 'an',\n",
              " 'nd',\n",
              " 'd_',\n",
              " '_m',\n",
              " 'ma',\n",
              " 'aî',\n",
              " 'ît',\n",
              " 'tr',\n",
              " 're',\n",
              " 'e_',\n",
              " '_d',\n",
              " 'di',\n",
              " 'it',\n",
              " 't_',\n",
              " '_o',\n",
              " 'on',\n",
              " 'n_',\n",
              " '_l',\n",
              " 'le',\n",
              " 'e_',\n",
              " '_m',\n",
              " 'ma',\n",
              " 'al',\n",
              " 'lh',\n",
              " 'he',\n",
              " 'eu',\n",
              " 'ur',\n",
              " 'r_',\n",
              " '_e',\n",
              " 'es',\n",
              " 'st',\n",
              " 't_',\n",
              " '_q',\n",
              " 'qu',\n",
              " \"u'\",\n",
              " \"'i\",\n",
              " 'il',\n",
              " 'l_',\n",
              " '_t',\n",
              " 'tu',\n",
              " 'ue',\n",
              " 'e_',\n",
              " '_s',\n",
              " 'se',\n",
              " 'es',\n",
              " 's_',\n",
              " '_é',\n",
              " 'él',\n",
              " 'lè',\n",
              " 'èv',\n",
              " 've',\n",
              " 'es',\n",
              " 'le_',\n",
              " '_te',\n",
              " 'tem',\n",
              " 'emp',\n",
              " 'mps',\n",
              " 'ps_',\n",
              " '_es',\n",
              " 'est',\n",
              " 'st_',\n",
              " '_un',\n",
              " 'un_',\n",
              " '_gr',\n",
              " 'gra',\n",
              " 'ran',\n",
              " 'and',\n",
              " 'nd_',\n",
              " '_ma',\n",
              " 'maî',\n",
              " 'aît',\n",
              " 'îtr',\n",
              " 'tre',\n",
              " 're_',\n",
              " '_di',\n",
              " 'dit',\n",
              " 'it_',\n",
              " '_on',\n",
              " 'on_',\n",
              " '_le',\n",
              " 'le_',\n",
              " '_ma',\n",
              " 'mal',\n",
              " 'alh',\n",
              " 'lhe',\n",
              " 'heu',\n",
              " 'eur',\n",
              " 'ur_',\n",
              " '_es',\n",
              " 'est',\n",
              " 'st_',\n",
              " '_qu',\n",
              " \"qu'\",\n",
              " \"u'i\",\n",
              " \"'il\",\n",
              " 'il_',\n",
              " '_tu',\n",
              " 'tue',\n",
              " 'ue_',\n",
              " '_se',\n",
              " 'ses',\n",
              " 'es_',\n",
              " '_él',\n",
              " 'élè',\n",
              " 'lèv',\n",
              " 'ève',\n",
              " 'ves',\n",
              " '_tem',\n",
              " 'temp',\n",
              " 'emps',\n",
              " 'mps_',\n",
              " '_est',\n",
              " 'est_',\n",
              " '_un_',\n",
              " '_gra',\n",
              " 'gran',\n",
              " 'rand',\n",
              " 'and_',\n",
              " '_maî',\n",
              " 'maît',\n",
              " 'aîtr',\n",
              " 'ître',\n",
              " 'tre_',\n",
              " '_dit',\n",
              " 'dit_',\n",
              " '_on_',\n",
              " '_le_',\n",
              " '_mal',\n",
              " 'malh',\n",
              " 'alhe',\n",
              " 'lheu',\n",
              " 'heur',\n",
              " 'eur_',\n",
              " '_est',\n",
              " 'est_',\n",
              " \"_qu'\",\n",
              " \"qu'i\",\n",
              " \"u'il\",\n",
              " \"'il_\",\n",
              " '_tue',\n",
              " 'tue_',\n",
              " '_ses',\n",
              " 'ses_',\n",
              " '_élè',\n",
              " 'élèv',\n",
              " 'lève',\n",
              " 'èves']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}